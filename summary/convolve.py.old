#!/usr/bin/env python

from __future__ import division
import matplotlib
from matplotlib import pyplot as plt
import numpy as np
from scipy import fft
from scipy.io import wavfile
import scipy.signal as sig
import tempfile
import os
import pathlib
import sys
import pyaudio
import librosa
import wave


from pytorch_msssim import ssim, ms_ssim, SSIM, MS_SSIM

import torchaudio
import torch



sr=16000

def play_sound(sound_data,SOUND_RECORD_SAMPLING_RATE):
  p = pyaudio.PyAudio()
  stream = p.open(format=pyaudio.paInt16, channels=1, rate=SOUND_RECORD_SAMPLING_RATE, output=True)
  #stream = p.open(format=pyaudio.paFloat32, channels=1, rate=SOUND_RECORD_SAMPLING_RATE, output=True)
  for i in range(int(sound_data.shape[0]/SOUND_RECORD_SAMPLING_RATE)):
     print("Playing : "+str(i*SOUND_RECORD_SAMPLING_RATE)+" -- "+str((i+1)*SOUND_RECORD_SAMPLING_RATE))
     stream.write(sound_data[i*SOUND_RECORD_SAMPLING_RATE:(i+1)*SOUND_RECORD_SAMPLING_RATE],SOUND_RECORD_SAMPLING_RATE)
  if int(sound_data.shape[0]/SOUND_RECORD_SAMPLING_RATE) * SOUND_RECORD_SAMPLING_RATE < sound_data.shape[0] :
     print("Playing : "+str(int(sound_data.shape[0]/SOUND_RECORD_SAMPLING_RATE) * SOUND_RECORD_SAMPLING_RATE)+" -- "+str(sound_data.shape[0]))
     stream.write(sound_data[int(sound_data.shape[0]/SOUND_RECORD_SAMPLING_RATE) * SOUND_RECORD_SAMPLING_RATE:],SOUND_RECORD_SAMPLING_RATE)
  stream.stop_stream()
  stream.close()
  p.terminate()

def plot_freqs(signal,sample_rate):
    #sampFreq=sample_rate
    #fft_spectrum = np.fft.rfft(signal)
    #freq = np.fft.rfftfreq(signal.size, d=1./sampFreq)
    #fft_spectrum_abs = np.abs(fft_spectrum)
    #plt.plot(freq, fft_spectrum_abs)
    #plt.xlabel("frequency, Hz")
    #plt.ylabel("Amplitude, units")
    #plt.show()

    #FFT
    t = np.arange(signal.shape[0])
    freq = np.fft.fftfreq(t.shape[-1])*sample_rate
    sp = np.fft.fft(signal)

    # Plot spectrum
    plt.plot(freq, abs(sp.real))
    plt.xlabel('Frequency (Hz)')
    plt.ylabel('Amplitude')
    plt.title('Spectrum of Signal')
    plt.show()
    #plt.xlim((0, 2000))
    #plt.grid()



def plot_wave(sound):
    plt.subplot(1,1,1)
    plt.plot(sound, 'b')
    plt.xlabel("Wave Plot")
    #plt.tight_layout()
    plt.show()

def pcm2float(sig, dtype='float32'):
    """Convert PCM signal to floating point with a range from -1 to 1.
    Use dtype='float32' for single precision.
    Parameters
    ----------
    sig : array_like
        Input array, must have integral type.
    dtype : data type, optional
        Desired (floating point) data type.
    Returns
    -------
    numpy.ndarray
        Normalized floating point data.
    See Also
    --------
    float2pcm, dtype
    """
    sig = np.asarray(sig)
    if sig.dtype.kind not in 'iu':
        raise TypeError("'sig' must be an array of integers")
    dtype = np.dtype(dtype)
    if dtype.kind != 'f':
        raise TypeError("'dtype' must be a floating point type")

    i = np.iinfo(sig.dtype)
    abs_max = 2 ** (i.bits - 1)
    offset = i.min + abs_max
    return (sig.astype(dtype) - offset) / abs_max

def getSpectrogram(data):
         sample_rate = 16000 ;  num_mfccs=4096
         #self.mfcc_transform_fn=torchaudio.transforms.MFCC(sample_rate=sample_rate,n_mfcc=num_mfccs,melkwargs={"n_fft": 400, "hop_length": 160, "n_mels": num_mfccs, "center": False},).to("cuda")
         mfcc_transform_fn=torchaudio.transforms.MFCC(sample_rate=sample_rate,n_mfcc=num_mfccs,melkwargs={"n_fft": 400, "hop_length": 160, "n_mels": num_mfccs, "center": False},)
         mfccs= mfcc_transform_fn( torch.Tensor(data) ).numpy()
         return mfccs

def saveRealAndGeneratedPlots(real_data,generated_data,saveToPath):
     #plt.clf()

     #generated_data=generated_data[int(abs(real_data.shape[0]-generated_data.shape[0])):] 
     generated_data=generated_data[:int(real_data.shape[0])] 

     generated_spectrogram=getSpectrogram(generated_data)
     generated_spectrogram=np.reshape(generated_spectrogram,(generated_spectrogram.shape[0],generated_spectrogram.shape[1],1))

     real_spectrogram=getSpectrogram(real_data)
     real_spectrogram=np.reshape(real_spectrogram,(real_spectrogram.shape[0],real_spectrogram.shape[1],1))

     MSE=np.square(np.subtract(real_data,generated_data)).mean()
     generated_spectrogram=np.reshape(generated_spectrogram,(1,1,generated_spectrogram.shape[0],generated_spectrogram.shape[1]))
     real_spectrogram=np.reshape(real_spectrogram,(1,1,real_spectrogram.shape[0],real_spectrogram.shape[1]))
     SSIM=ssim( torch.Tensor(generated_spectrogram), torch.Tensor(real_spectrogram), data_range=255, size_average=True).item()

     plt.subplot(1,1,1)
     minValue=np.min(real_data)
     minValue2=np.min(generated_data)
     if minValue2 < minValue:
        minValue=minValue2

     plt.plot(real_data,color='r', label='real_data')
     plt.plot(generated_data,color='b', label='generated_data')
     plt.text(3300, minValue+0.1, f"MSE={float(MSE):.4f}\nSSIM={float(SSIM):.4f}", style='italic',
        bbox={'facecolor': 'red', 'alpha': 0.5, 'pad': 10})

     #plt.title(title)
     plt.xlabel('Time')
     plt.ylabel('Amlpitude')
     plt.legend(loc = "upper right")

     plt.savefig(saveToPath)

     plt.close()

padsize=1000

SILENCE_SECONDS_TRANSMITTER=2

transmit_fname=sys.argv[1]
rir_fname=sys.argv[2]


rate,transmit_data=wavfile.read(transmit_fname)
transmit_data_1d=transmit_data[:,0]+transmit_data[:,1]
transmit_data=librosa.resample(transmit_data_1d, orig_sr=44100, target_sr=16000)# transmit_data_1d[SILENCE_SECONDS_TRANSMITTER*rate:-SILENCE_SECONDS_TRANSMITTER*rate]

#play_sound(transmit_data,rate)
#plot_freqs(transmit_data,rate)
#plot_wave(transmit_data)


rate,rir_data=wavfile.read(rir_fname)
if rate > 16000 :
   rir_data=librosa.resample(rir_data, orig_sr=rate, target_sr=16000)# transmit_data_1d[SILENCE_SECONDS_TRANSMITTER*rate:-SILENCE_SECONDS_TRANSMITTER*rate]

#print(rir_data.shape)
#print(rir_data)
#print(transmit_data.shape)
print(np.max(rir_data))
#print(transmit_data)
reverbed_data=sig.fftconvolve(transmit_data,rir_data,'full')
#receive_data=receive_data/3000000
#play_sound(receive_data,rate)
#plot_freqs(receive_data,rate)
#plot_wave(receive_data)


reverbed_data_sum=np.sum(np.abs(reverbed_data))
transmit_data_sum=np.sum(np.abs(transmit_data))
ratio=transmit_data_sum/reverbed_data_sum
#ratio=1/20

reverbed_data=reverbed_data*ratio


wavfile.write( rir_fname+'.reverbed.wav',16000,np.array(reverbed_data).astype(np.float32))

saveRealAndGeneratedPlots(transmit_data,reverbed_data,rir_fname+'.r.a.g.png')


#writer = wave.open(rir_fname+'.reverbed.wav', 'wb')
#writer.setnchannels(1) # 1 channel, mono (one channel is active at an instance)
#writer.setsampwidth(2) # 16bit
#writer.setframerate(rate) # sample rate
##writer.writeframes(ir_receive_data.astype(np.int16).tostring())
##writer.writeframes(receive_data.astype(np.int16).tostring())
#writer.writeframes(receive_data.tostring())
#print(rir_fname+'.reverbed.wav')
#writer.close()

