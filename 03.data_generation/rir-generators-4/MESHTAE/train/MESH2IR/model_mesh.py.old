import torch
import torch.nn as nn
import torch.nn.parallel
from miscc.config import cfg
#from miscc.utils import mask_test_edges
from torch.autograd import Variable
import numpy as np
from torch_geometric.nn import GCNConv, GATConv,TopKPooling
from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp
from torch_geometric.utils import to_dense_adj, to_dense_batch, dropout_adj,unbatch

import torch.nn.functional as F
import scipy.sparse as sp

import traceback
from torchinfo import summary
import math


import torch.nn.functional as F
from einops import repeat
from einops import rearrange, repeat
from einops.layers.torch import Rearrange
#### bu net degil : from chamfer_dist import ChamferDistanceL1
#from chamferdist import ChamferDistance
import copy
import numpy as np
import math
from functools import partial

import torch
import timm.models.vision_transformer

from timm.models.vision_transformer import PatchEmbed, Block



        

class MESH_VAE(nn.Module):
        def __init__(self):
                super(MESH_VAE,self).__init__()
                self.LATENT_VECTOR_SIZE=128
                self.FEATURES_PER_FACE=16 # triangle_coords (9= v1.xyz, v2.xyz, v3.xyz) , center coords (3), Norml Vector(3), Area (1), 3+3+1=7


                self.transformer = Transformer(vocab_size=, masking=masking, d_model_encoder=d_model_encoder, h_encoder=h_encoder, d_k_encoder=d_k_encoder, d_v_encoder=d_v_encoder, d_ff_encoder=d_ff_encoder, number_of_encoder_blocks=number_of_encoder_blocks, d_model_decoder=d_model_decoder, h_decoder=h_decoder, d_k_decoder=d_k_decoder, d_v_decoder=d_v_decoder, d_ff_decoder=d_ff_decoder, number_of_decoder_blocks=number_of_decoder_blocks)



                self.encoder_linear_1= torch.nn.Linear(cfg.MAX_FACE_COUNT*self.FEATURES_PER_FACE,10)
                self.encoder_linear_2= torch.nn.Linear(10,self.LATENT_VECTOR_SIZE)
                self.encoder_batch_norm= torch.nn.BatchNorm1d(self.LATENT_VECTOR_SIZE)

                self.encoder_vae_mean = torch.nn.Linear( self.LATENT_VECTOR_SIZE, self.LATENT_VECTOR_SIZE) 
                self.encoder_vae_logstd = torch.nn.Linear( self.LATENT_VECTOR_SIZE, self.LATENT_VECTOR_SIZE)
                self.decoder_1= torch.nn.Linear(self.LATENT_VECTOR_SIZE,10) 
                self.decoder_2= torch.nn.Linear(10,cfg.MAX_FACE_COUNT*self.FEATURES_PER_FACE) 
                self.decoder_batch_norm= torch.nn.BatchNorm1d(cfg.MAX_FACE_COUNT*self.FEATURES_PER_FACE)
                
        def encode(self,X):
                
                z = torch.relu(self.encoder_linear_1(X))
                z = torch.relu(self.encoder_linear_2(z))
                z = self.encoder_batch_norm(z)
                mean = self.encoder_vae_mean(z)
                logstd = self.encoder_vae_logstd(z)
                gaussian_noise = torch.randn(1,self.LATENT_VECTOR_SIZE).cuda()
                sampled_z = gaussian_noise*torch.exp(logstd) + mean
                sampled_z = sampled_z.squeeze()
                return sampled_z,mean,logstd
                
        def forward(self,X):
                Z,mean,logstd= self.encode(X)
                X_predicted = self.decode(Z)
                return X_predicted,mean,logstd

        def decode(self,Z):
                X_predicted=torch.relu(self.decoder_1(Z))
                X_predicted=torch.relu(self.decoder_2(X_predicted))
                X_predicted=self.decoder_batch_norm(X_predicted)
                return X_predicted
              
        def loss(self,X_pred,X,mean,logstd) :
              lossX = F.mse_loss(X_pred,X)
              kl_divergence = 0.5/ X_pred.size(0) * (1 + 2*logstd - mean**2 - torch.exp(logstd)**2).sum(1).mean()
              QX=0.5
              QKL=0.5
              loss = QX*lossX -QKL*kl_divergence 
              return loss
              

